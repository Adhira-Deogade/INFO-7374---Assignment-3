{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Expt1-BoW-Just pre-processing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adhira-Deogade/INFO-7374---Assignment-3/blob/master/Expt1_BoW_Just_pre_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xIa68u7pYWIQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rTmfEANWS1Ho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wKIGXK9HOfyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Get a list of stop words from NLTK package"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Op5HjdIMwJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPw_64zZM7Qn",
        "colab_type": "code",
        "outputId": "a97f59bb-1006-4f89-f17c-81a3ff341790",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import os\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras import utils\n",
        "\n",
        "# This code was tested with TensorFlow v1.4\n",
        "print(\"You have TensorFlow version\", tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You have TensorFlow version 1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "O66kQ7PLNBV_",
        "colab_type": "code",
        "outputId": "79dfa795-7b7b-4950-85ac-4b7d5b7c0b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " cleanedfinancial_data.csv   JGEPart1.txt         Part1-GE.json   X.pickle\n",
            " \u001b[0m\u001b[01;34mFinalFiles\u001b[0m/                'Part1-GE (1).json'   \u001b[01;34msample_data\u001b[0m/    y.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xQ09Ka6w1Qkx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "94HBiUhZ1kg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "upload = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i6GmYebdNEJM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Our file is present, just import it"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "epKvyu25NHdq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"cleanedfinancial_data.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3yNnGK_uNKan",
        "colab_type": "code",
        "outputId": "4e905b01-116e-4a85-b228-f4a45463f8cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Good day, ladies and gentlemen, and welcome to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>I'm not sure. I think Model T was a little bit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Well, we need to bring the Shanghai factory on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>neutral</td>\n",
              "      <td>So it's - it is eligible for that. But it soun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>positive</td>\n",
              "      <td>The demand for - the demand for Model 3 is ins...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 sentiment                                               text\n",
              "0           0   neutral  Good day, ladies and gentlemen, and welcome to...\n",
              "1           1  negative  I'm not sure. I think Model T was a little bit...\n",
              "2           2  negative  Well, we need to bring the Shanghai factory on...\n",
              "3           3   neutral  So it's - it is eligible for that. But it soun...\n",
              "4           4  positive  The demand for - the demand for Model 3 is ins..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "vhaw0eV_NL0o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataset.drop(columns=\"Unnamed: 0\", inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vMZHQNn4NZDu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Value counts"
      ]
    },
    {
      "metadata": {
        "id": "5KJtxd6NNPuX",
        "colab_type": "code",
        "outputId": "2cb2094a-d64a-485b-8aec-2afe6f2420dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.sentiment.value_counts()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral     838\n",
              "positive    654\n",
              "negative    157\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "zIS9mJ_V1tAi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Data is imbalanced, therefore, we first build a logistic regression model as our base model**"
      ]
    },
    {
      "metadata": {
        "id": "PyQ6YbYn18eu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MoASa35V18br",
        "colab_type": "code",
        "outputId": "09e2c114-6ae7-49fa-d7bf-dfd133ee49a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.shape[0]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1649"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "Gn5YOgev18Zf",
        "colab_type": "code",
        "outputId": "c546c406-4aa0-4bb4-e46c-56354a06bf49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.iloc[2,1]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Well, we need to bring the Shanghai factory online. I think that's the biggest driver for getting to 500K plus a year. Our car is just very expensive going into China. We've got import duties. We've got transport costs. We've got higher-cost labor here. And we've never been eligible for any of the EV tax credits. A lot of people sort of dependent on incentives. In fact, we are [indiscernible] EVs, we have the least access to incentives. It's pretty crazy because there's so many companies that - countries that have put price caps on the EV incentive, which affects Tesla. And in China, which is the biggest market for EVs, we've never had any subsidies or tax incentives for vehicles.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "8gYCLu64UJKo",
        "colab_type": "code",
        "outputId": "6993eb1c-ef68-4c02-d110-b0c43f9d14b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize as wt \n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#spell correction\n",
        "# import autocorrect\n",
        "# from autocorrect. import spell"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T18hqSxzV01k",
        "colab_type": "code",
        "outputId": "cf00ba65-5725-4a16-cdf7-66af87b90437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1649, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "b3UAT-t6T8jS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kulPmt7E18Vf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(dataset.shape[0]):\n",
        "    sms = dataset.iloc[i, 1]\n",
        "\n",
        "    # remove non alphabatic characters\n",
        "    sms = re.sub('[^A-Za-z]', ' ', sms)\n",
        "\n",
        "    # make words lowercase, because Go and go will be considered as two words\n",
        "    sms = sms.lower()\n",
        "\n",
        "    # tokenising\n",
        "    tokenized_sms = wt(sms)\n",
        "\n",
        "    # remove stop words and stemming\n",
        " \n",
        "    sms_processed = []\n",
        "    for word in tokenized_sms:\n",
        "        if word not in set(stopwords.words('english')):\n",
        "            sms_processed.append(stemmer.stem(word))\n",
        "\n",
        "    sms_text = \" \".join(sms_processed)\n",
        "    data.append(sms_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oD6g--TlViye",
        "colab_type": "code",
        "outputId": "222af54d-500d-4385-cc33-7889a85bc844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1649"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "w6UHBEkN18Sv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# creating the feature matrix \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "matrix = CountVectorizer(max_features = 2000, min_df = 3, max_df = 0.6, stop_words = stopwords.words('english'))\n",
        "X = matrix.fit_transform(data).toarray()\n",
        "y = dataset.iloc[:, 0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n-kkDBOl18RL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}